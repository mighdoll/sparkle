sparkle-time-server { // TODO rename to sparkle
  
  logging {
    // zookeeper and kafka are hard coded to use log4j
    provider = log4j
    
    levels {
      root = DEBUG
      kafka.network = WARN
      kafka.utils = WARN
      kafka.client = WARN 
      kafka.consumer = ERROR
      kafka.consumer.SimpleConsumer = ERROR
      kafka.producer.SyncProducer = WARN
      kafka.producer.BrokerPartitionInfo = ERROR
      kafka.producer.async.DefaultEventHandler = FATAL
      com.datastax = WARN
      org.apache.zookeeper.ClientCnxn = ERROR
      nest.sparkle = DEBUG
      nest.sparkle.loader.kafka.KafkaTopicLoader = DEBUG
      nest.sparkle.loader.kafka.KafkaReader = TRACE
    }
    
    file {
      path = "/tmp/sparkle-kafka-tests.log"
      level = TRACE
    }
        
  }
  
  measure {
    metrics-gateway {
      enable = false
    }
    
    tsv-gateway {
      enable = true
      file = "/tmp/kafka-loader-measurements.tsv"
    }
  }
  
  kafka-loader {
    //message-commit-limit = 10
    //max-concurrent-writes = 200
    
    reader {
      // the kafka reader uses a consumer group per topic to avoid issues restarting the
      consumer-group-prefix = "itConsumer"
      consumer-group-prefix = ${?SPARKLE_CONSUMER_GROUP_PREFIX}
    }
  }

}
